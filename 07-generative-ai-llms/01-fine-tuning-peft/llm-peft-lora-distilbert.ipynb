{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be94e6d6-4096-4d1a-aa58-5afd89f33bff",
      "metadata": {
        "id": "be94e6d6-4096-4d1a-aa58-5afd89f33bff"
      },
      "source": [
        "# Parameter Efficient Fine Tuning - LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e128f6ad",
      "metadata": {},
      "source": [
        "The purpose of this notebook is to fine tune \"distilbert\" using PEFT - LoRA technique."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mkgJdkPf9i2F",
      "metadata": {
        "id": "mkgJdkPf9i2F"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7uqRnY_w9kkt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uqRnY_w9kkt",
        "outputId": "cb342597-8beb-4ce1-940c-c9af37eb714a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install peft\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jQyAJlJE9Mgg",
      "metadata": {
        "id": "jQyAJlJE9Mgg"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4ef8ea85-d04d-4217-99a3-21c446bf2ffa",
      "metadata": {
        "id": "4ef8ea85-d04d-4217-99a3-21c446bf2ffa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer)\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa6a4484-07d8-49dd-81ef-672105f53ebe",
      "metadata": {
        "id": "aa6a4484-07d8-49dd-81ef-672105f53ebe"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fa9722d3-0609-4aea-9585-9aa2cfc1fc9a",
      "metadata": {
        "id": "fa9722d3-0609-4aea-9585-9aa2cfc1fc9a"
      },
      "outputs": [],
      "source": [
        "# load imdb data\n",
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# define subsample size\n",
        "N = 1000\n",
        "\n",
        "# generate indexes for random subsample\n",
        "rand_idx = np.random.randint(24999, size=N)\n",
        "\n",
        "# extract train and test data\n",
        "x_train = imdb_dataset['train'][rand_idx]['text']\n",
        "y_train = imdb_dataset['train'][rand_idx]['label']\n",
        "\n",
        "x_test = imdb_dataset['test'][rand_idx]['text']\n",
        "y_test = imdb_dataset['test'][rand_idx]['label']\n",
        "\n",
        "# create new dataset\n",
        "dataset = DatasetDict({\n",
        "                        'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n",
        "                        'validation':Dataset.from_dict({'label':y_test,'text':x_test})\n",
        "                      })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "de226234-c521-4577-802c-0e7079ef4364",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de226234-c521-4577-802c-0e7079ef4364",
        "outputId": "48c31ee3-bcd9-488c-e913-795209062403"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load dataset\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d5625faa-5fea-4334-bd38-b77de983d8a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5625faa-5fea-4334-bd38-b77de983d8a8",
        "outputId": "76971e34-d9a7-4267-efda-a9fcfeac0ce7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.503"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display % of training data with label=1\n",
        "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3644c68d-9adf-48a4-90a2-8fd89555a302",
      "metadata": {
        "id": "3644c68d-9adf-48a4-90a2-8fd89555a302"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a60dd1fe-8144-4678-b018-20891e49237a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a60dd1fe-8144-4678-b018-20891e49237a",
        "outputId": "3798b0d3-ec42-4b1b-8847-cd0723a4463a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_checkpoint = 'distilbert-base-uncased'  #  'roberta-base'\n",
        "\n",
        "# define label maps\n",
        "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
        "label2id = {\"Negative\":0, \"Positive\":1}\n",
        "\n",
        "# generate classification model from model_checkpoint\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "853002f8-d39c-4bc4-8d07-e44a47de3b47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "853002f8-d39c-4bc4-8d07-e44a47de3b47",
        "outputId": "3baa793c-064c-4caf-8954-a9bb804a86ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display architecture\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc98609-873d-455c-bac4-155632cda484",
      "metadata": {
        "id": "4bc98609-873d-455c-bac4-155632cda484"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7fe08707-657f-4e66-aa72-84899c54bf8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fe08707-657f-4e66-aa72-84899c54bf8d",
        "outputId": "ea243ebc-a0bc-4167-a616-0cd6b05bdf59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# create tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(                      # automatically loads the correct tokenizer associated with your pre-trained model\n",
        "                                          model_checkpoint,     # model identifier\n",
        "                                          add_prefix_space=True # This argument is model-specific. Some models (especially those based on subword tokenization like RoBERTa) benefit from having a space added before words that start sentences\n",
        "                                        )\n",
        "\n",
        "# add pad token if none exists\n",
        "if tokenizer.pad_token is None:                         # checks whether the loaded tokenizer has a dedicated padding token\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})# allows you to introduce custom special tokens to the tokenizer's vocabulary\n",
        "    model.resize_token_embeddings(len(tokenizer))       # resizes the model's embedding layer to accommodate the newly added token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "20f4adb9-ce8f-4f54-9b94-300c9daae1b8",
      "metadata": {
        "id": "20f4adb9-ce8f-4f54-9b94-300c9daae1b8"
      },
      "outputs": [],
      "source": [
        "# create tokenize function\n",
        "def tokenize_function(examples):\n",
        "    # extract text\n",
        "    text = examples[\"text\"]\n",
        "\n",
        "    #tokenize and truncate text\n",
        "    tokenizer.truncation_side = \"left\"  # truncate (shorten) sequences that are longer than the maximum allowed length (max_length) by removing tokens from the left side (beginning) of the sequence.\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",            # return the tokenized outputs as NumPy arrays, which is often the preferred format for working with PyTorch models\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b7600bcd-7e93-4fb4-bd8d-ffc76bed1ac2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251,
          "referenced_widgets": [
            "e14e169158594193958575050366ef0a",
            "03580e901932460693cf3cce4029fd55",
            "4278c10f08ac46b892ffd9499378a819",
            "0db95c9492a243fe9b6bb4236a8fb298",
            "7b1306ce1bf048a7ad14d0be2e8f9703",
            "82c22b7ae5ca4ca6926f9a4e4e84a4d6",
            "bf37c990fcfe465cba7e54e4a9ccf913",
            "515c66fe0edd4012bcd32777743e0d22",
            "70661c3a30424943ac1267ecfa13f47b",
            "9a2d075a9bc34797ab989b163cc6cfcb",
            "ff649881c70f49e3a4ca66d2cd21a827",
            "5eb180614e0b4cf4877cf84f470ad4c6",
            "a1819457e733404c9966029bae1e629a",
            "507a334a74b640a38239b6460d62fd4e",
            "23ba292865014550801d4b821f9a9f2b",
            "1c7f4c7898794524b3e90a5067045a75",
            "0ac1d759782a42b7b6e5b7d6ce6b7fa4",
            "ed41eca7c78d48e8b4c08f0df59a432b",
            "b81c4414d9c64cf8913a6be7a63a416d",
            "e4783ca0756c4688b61df5f944c2d088",
            "65bc4dc2cd044853b95c094e5bfe84e3",
            "552f2d589aa54b18b7601af6f48ad61e"
          ]
        },
        "id": "b7600bcd-7e93-4fb4-bd8d-ffc76bed1ac2",
        "outputId": "c74f945b-b03a-4d23-919c-dbc0a8cae8ad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e14e169158594193958575050366ef0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5eb180614e0b4cf4877cf84f470ad4c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tokenize training and validation datasets\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3f8e85f9-1804-4f49-a783-4da59580ea1e",
      "metadata": {
        "id": "3f8e85f9-1804-4f49-a783-4da59580ea1e"
      },
      "outputs": [],
      "source": [
        "# create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cd9a120-580d-470c-a981-7c7e22604865",
      "metadata": {
        "id": "3cd9a120-580d-470c-a981-7c7e22604865"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2a894819-2e9c-4a53-9790-32130c182bca",
      "metadata": {
        "id": "2a894819-2e9c-4a53-9790-32130c182bca"
      },
      "outputs": [],
      "source": [
        "# import accuracy evaluation metric\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c07b9be2-a3f6-4b38-b9e8-6a2bc8aa945a",
      "metadata": {
        "id": "c07b9be2-a3f6-4b38-b9e8-6a2bc8aa945a"
      },
      "outputs": [],
      "source": [
        "# define an evaluation function to pass into trainer later\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47500035-a555-46e0-83dc-440586d96b7e",
      "metadata": {
        "id": "47500035-a555-46e0-83dc-440586d96b7e"
      },
      "source": [
        "### Apply untrained model to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8f3761c1-a297-45c8-882e-d74856259810",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f3761c1-a297-45c8-882e-d74856259810",
        "outputId": "a380469e-7716-419e-a1a9-8f81902a515b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Untrained model predictions:\n",
            "----------------------------\n",
            "It was good. - Negative\n",
            "Not a fan, don't recommed. - Negative\n",
            "Better than the first one. - Negative\n",
            "This is not worth watching even once. - Negative\n",
            "This one is a pass. - Negative\n"
          ]
        }
      ],
      "source": [
        "# define list of examples\n",
        "text_list = [\"It was good.\",\n",
        "             \"Not a fan, don't recommed.\",\n",
        "             \"Better than the first one.\",\n",
        "             \"This is not worth watching even once.\",\n",
        "             \"This one is a pass.\"\n",
        "            ]\n",
        "\n",
        "print(\"Untrained model predictions:\")\n",
        "print(\"----------------------------\")\n",
        "for text in text_list:\n",
        "    # tokenize text\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\")  # converts the text into a sequence of token IDs that the model can understand.\n",
        "    # compute logits\n",
        "    logits = model(inputs).logits                         # runs the forward pass of the model on the input data and extracts the raw output scores (logits) from the model's output\n",
        "    # convert logits to label\n",
        "    predictions = torch.argmax(logits)                    # converts the logits into a final prediction\n",
        "\n",
        "    print(text + \" - \" + id2label[predictions.tolist()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff356f78-c9fd-4f2b-8f5b-097cf29c1c08",
      "metadata": {
        "id": "ff356f78-c9fd-4f2b-8f5b-097cf29c1c08"
      },
      "source": [
        "## Apply PEFT - LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e4dde538-cd7f-4ab5-a96d-c30f3003822e",
      "metadata": {
        "id": "e4dde538-cd7f-4ab5-a96d-c30f3003822e"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(                           # This is a configuration class for the LoRA method, which is part of the PEFT library.\n",
        "                        task_type=\"SEQ_CLS\",        # This specifies that the task is sequence classification. SEQ_CLS stands for Sequence Classification, indicating that the model will be used to classify entire sequences (like sentences or documents).\n",
        "                        r=4,                        # This is the rank of the LoRA update matrices. It determines the number of trainable parameters and the capacity of the adaptation. A lower rank means fewer parameters but potentially less expressive power.\n",
        "                        lora_alpha=32,              # This is the scaling factor for the LoRA update. It affects how much influence the LoRA adaptation has compared to the original weights.\n",
        "                        lora_dropout=0.01,          # This sets the dropout probability for LoRA layers. Dropout helps prevent overfitting during training.\n",
        "                        target_modules = ['q_lin']) # This specifies which modules in the model to apply LoRA to. In this case, it's targeting only the query linear layer ('q_lin') of the attention mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f1391303-1e16-4d5c-b2b4-799997eff9f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1391303-1e16-4d5c-b2b4-799997eff9f8",
        "outputId": "aefd17e9-37bd-4e05-d331-d69a1fbcba8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, r=4, target_modules={'q_lin'}, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "peft_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3e0d9408-9fc4-4bd3-8d35-4d8217fe01e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e0d9408-9fc4-4bd3-8d35-4d8217fe01e2",
        "outputId": "4dbbf2a4-e232-458a-821b-e76c2713cdd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n"
          ]
        }
      ],
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5db78059-e5ae-4807-89db-b58ef6abedd1",
      "metadata": {
        "id": "5db78059-e5ae-4807-89db-b58ef6abedd1"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 1e-3       # learning rate\n",
        "batch_size = 4  # number of samples in each batch\n",
        "num_epochs = 10 # number of times to iterate over the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9244ed55-65a4-4c66-8388-55efd87bceb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9244ed55-65a4-4c66-8388-55efd87bceb8",
        "outputId": "c5af7431-ad61-4168-fc85-d6dd7d4e06ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# define training arguments\n",
        "training_args = TrainingArguments(          # provides a convenient way to set hyperparameters and other training configurations\n",
        "    output_dir=model_checkpoint + \"-lora-text-classification\", # output directory\n",
        "    learning_rate=lr,                       # learning rate\n",
        "    per_device_train_batch_size=batch_size, # Sets the batch size per device for training\n",
        "    per_device_eval_batch_size=batch_size,  # Sets the batch size per device for evaluation\n",
        "    num_train_epochs=num_epochs,            # number of epochs for training\n",
        "    weight_decay=0.01,                      # Applies weight decay (L2 regularization) to the model's parameters\n",
        "    evaluation_strategy=\"epoch\",            # Evaluates the model's performance on the evaluation set at the end of each epoch.\n",
        "    save_strategy=\"epoch\",                  # Saves a model checkpoint at the end of each epoch.\n",
        "    load_best_model_at_end=True,            # After training, loads the best-performing model (based on evaluation metrics) from the saved checkpoints\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "fc8bc705-5dd7-4305-a797-399b2b0fa2c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "fc8bc705-5dd7-4305-a797-399b2b0fa2c7",
        "outputId": "e43c060f-fc63-4ce0-dc3b-6af13bc546d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 07:46, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.492492</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.388000</td>\n",
              "      <td>0.445441</td>\n",
              "      <td>0.878000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.388000</td>\n",
              "      <td>0.668202</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.149300</td>\n",
              "      <td>0.620600</td>\n",
              "      <td>0.878000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.149300</td>\n",
              "      <td>0.788578</td>\n",
              "      <td>0.883000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.041600</td>\n",
              "      <td>0.941812</td>\n",
              "      <td>0.877000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.041600</td>\n",
              "      <td>0.918641</td>\n",
              "      <td>0.888000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.016100</td>\n",
              "      <td>0.981108</td>\n",
              "      <td>0.882000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.016100</td>\n",
              "      <td>0.972565</td>\n",
              "      <td>0.884000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.007400</td>\n",
              "      <td>1.005077</td>\n",
              "      <td>0.883000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2500, training_loss=0.12047329349517823, metrics={'train_runtime': 467.8911, 'train_samples_per_second': 21.372, 'train_steps_per_second': 5.343, 'total_flos': 1099854434924064.0, 'train_loss': 0.12047329349517823, 'epoch': 10.0})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " # creater trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,                                  # The pre-trained model you're fine-tuning.\n",
        "    args=training_args,                           # The TrainingArguments object you defined earlier.\n",
        "    train_dataset=tokenized_dataset[\"train\"],     # Your tokenized training dataset.\n",
        "    eval_dataset=tokenized_dataset[\"validation\"], # Your tokenized validation dataset.\n",
        "    tokenizer=tokenizer,                          # The tokenizer associated with your model.\n",
        "    data_collator=data_collator,                  # this will dynamically pad examples in each batch to be equal length\n",
        "    compute_metrics=compute_metrics,              # A function you've defined to calculate evaluation metrics during training.\n",
        ")\n",
        "\n",
        "# train model\n",
        "trainer.train()                                   # starts the training process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f5664d1-9bd2-4ce1-bc24-cab5adf80f49",
      "metadata": {
        "id": "6f5664d1-9bd2-4ce1-bc24-cab5adf80f49"
      },
      "source": [
        "## Generate prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e5dc029e-1c16-491d-a3f1-715f9e0adf52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5dc029e-1c16-491d-a3f1-715f9e0adf52",
        "outputId": "33c37b98-4b61-4a94-d040-a2ed0dc83a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained model predictions:\n",
            "--------------------------\n",
            "It was good. - Positive\n",
            "Not a fan, don't recommed. - Negative\n",
            "Better than the first one. - Positive\n",
            "This is not worth watching even once. - Negative\n",
            "This one is a pass. - Negative\n"
          ]
        }
      ],
      "source": [
        "model.to('cuda') # moving to 'mps' for Mac (can alternatively do 'cpu')\n",
        "\n",
        "print(\"Trained model predictions:\")\n",
        "print(\"--------------------------\")\n",
        "for text in text_list:\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cuda\") # moving to 'mps' for Mac (can alternatively do 'cpu')\n",
        "\n",
        "    logits = model(inputs).logits\n",
        "    predictions = torch.max(logits,1).indices\n",
        "\n",
        "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c084bd9e-f7b1-4979-b753-73335ee0cede",
      "metadata": {
        "id": "c084bd9e-f7b1-4979-b753-73335ee0cede"
      },
      "source": [
        "## Optional: Push Model to HuggingFace Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159eb49a-dd0d-4c9e-b9ab-27e06585fd84",
      "metadata": {
        "id": "159eb49a-dd0d-4c9e-b9ab-27e06585fd84"
      },
      "outputs": [],
      "source": [
        "# option 1: notebook login\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login() # ensure token gives write access\n",
        "\n",
        "# # option 2: key login\n",
        "# from huggingface_hub import login\n",
        "# write_key = 'hf_' # paste token here\n",
        "# login(write_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09496307-e253-47e3-a46f-3f28a84c89a7",
      "metadata": {
        "id": "09496307-e253-47e3-a46f-3f28a84c89a7"
      },
      "outputs": [],
      "source": [
        "hf_name = 'nikhilkomakula' # your hf username or org name\n",
        "model_id = hf_name + \"/\" + model_checkpoint + \"-lora-text-classification\" # you can name the model whatever you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c56ea581-0ea3-45f3-af21-362e9093ee37",
      "metadata": {
        "id": "c56ea581-0ea3-45f3-af21-362e9093ee37"
      },
      "outputs": [],
      "source": [
        "model.push_to_hub(model_id) # save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f487331a-8552-4fb2-867f-985b8fe1d1ab",
      "metadata": {
        "id": "f487331a-8552-4fb2-867f-985b8fe1d1ab"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(model_id) # save trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e7feaa-b70e-4b1d-a118-23c616d14639",
      "metadata": {
        "id": "00e7feaa-b70e-4b1d-a118-23c616d14639"
      },
      "source": [
        "## Optional: Load PEFT Model from HuggingFace Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19cffa01-25a4-4c86-a7fa-a84353b8caae",
      "metadata": {
        "id": "19cffa01-25a4-4c86-a7fa-a84353b8caae"
      },
      "outputs": [],
      "source": [
        "# how to load peft model from hub for inference\n",
        "config = PeftConfig.from_pretrained(model_id)\n",
        "inference_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    config.base_model_name_or_path, num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "model = PeftModel.from_pretrained(inference_model, model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77c6ed42-8ec3-4343-9e42-405feac052ba",
      "metadata": {
        "id": "77c6ed42-8ec3-4343-9e42-405feac052ba"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "c084bd9e-f7b1-4979-b753-73335ee0cede",
        "00e7feaa-b70e-4b1d-a118-23c616d14639"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03580e901932460693cf3cce4029fd55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c22b7ae5ca4ca6926f9a4e4e84a4d6",
            "placeholder": "​",
            "style": "IPY_MODEL_bf37c990fcfe465cba7e54e4a9ccf913",
            "value": "Map: 100%"
          }
        },
        "0ac1d759782a42b7b6e5b7d6ce6b7fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db95c9492a243fe9b6bb4236a8fb298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a2d075a9bc34797ab989b163cc6cfcb",
            "placeholder": "​",
            "style": "IPY_MODEL_ff649881c70f49e3a4ca66d2cd21a827",
            "value": " 1000/1000 [00:01&lt;00:00, 699.45 examples/s]"
          }
        },
        "1c7f4c7898794524b3e90a5067045a75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ba292865014550801d4b821f9a9f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65bc4dc2cd044853b95c094e5bfe84e3",
            "placeholder": "​",
            "style": "IPY_MODEL_552f2d589aa54b18b7601af6f48ad61e",
            "value": " 1000/1000 [00:01&lt;00:00, 716.51 examples/s]"
          }
        },
        "4278c10f08ac46b892ffd9499378a819": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_515c66fe0edd4012bcd32777743e0d22",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70661c3a30424943ac1267ecfa13f47b",
            "value": 1000
          }
        },
        "507a334a74b640a38239b6460d62fd4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81c4414d9c64cf8913a6be7a63a416d",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4783ca0756c4688b61df5f944c2d088",
            "value": 1000
          }
        },
        "515c66fe0edd4012bcd32777743e0d22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "552f2d589aa54b18b7601af6f48ad61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eb180614e0b4cf4877cf84f470ad4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1819457e733404c9966029bae1e629a",
              "IPY_MODEL_507a334a74b640a38239b6460d62fd4e",
              "IPY_MODEL_23ba292865014550801d4b821f9a9f2b"
            ],
            "layout": "IPY_MODEL_1c7f4c7898794524b3e90a5067045a75"
          }
        },
        "65bc4dc2cd044853b95c094e5bfe84e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70661c3a30424943ac1267ecfa13f47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b1306ce1bf048a7ad14d0be2e8f9703": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c22b7ae5ca4ca6926f9a4e4e84a4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2d075a9bc34797ab989b163cc6cfcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1819457e733404c9966029bae1e629a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ac1d759782a42b7b6e5b7d6ce6b7fa4",
            "placeholder": "​",
            "style": "IPY_MODEL_ed41eca7c78d48e8b4c08f0df59a432b",
            "value": "Map: 100%"
          }
        },
        "b81c4414d9c64cf8913a6be7a63a416d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf37c990fcfe465cba7e54e4a9ccf913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e14e169158594193958575050366ef0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03580e901932460693cf3cce4029fd55",
              "IPY_MODEL_4278c10f08ac46b892ffd9499378a819",
              "IPY_MODEL_0db95c9492a243fe9b6bb4236a8fb298"
            ],
            "layout": "IPY_MODEL_7b1306ce1bf048a7ad14d0be2e8f9703"
          }
        },
        "e4783ca0756c4688b61df5f944c2d088": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed41eca7c78d48e8b4c08f0df59a432b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff649881c70f49e3a4ca66d2cd21a827": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
