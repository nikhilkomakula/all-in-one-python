{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function to implement linear regression from scratch using gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 638\n",
      "Weights: [1.11803122 1.11803122]\n",
      "Bias: 5.990249192151607\n",
      "Final cost: 4.850437962270154e-05\n",
      "Predictions: [2.99025662 4.99025167 6.99024672 8.99024177]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def linear_regression(X, y, learning_rate=0.01, num_iterations=1000):\n",
    "#     n_samples, n_features = X.shape\n",
    "#     weights = np.zeros(n_features)\n",
    "#     bias = 0\n",
    "\n",
    "#     for _ in range(num_iterations):\n",
    "#         y_pred = np.dot(X, weights) + bias\n",
    "#         print(y_pred)\n",
    "#         d_weights = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
    "#         d_bias = (1/n_samples) * np.sum(y_pred - y)\n",
    "#         weights -= learning_rate * d_weights\n",
    "#         bias -= learning_rate * d_bias\n",
    "\n",
    "#     return weights, bias\n",
    "\n",
    "# # Example usage\n",
    "# X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "# y = np.array([3, 5, 7, 9])\n",
    "# weights, bias = linear_regression(X, y)\n",
    "# print(\"weights:\", weights)\n",
    "# print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 638\n",
      "Weights: [1.11803122 1.11803122]\n",
      "Bias: 5.990249192151607\n",
      "Final cost: 4.850437962270154e-05\n",
      "Predictions: [2.99025662 4.99025167 6.99024672 8.99024177]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_regression(X, y, learning_rate=0.01, num_iterations=1000, tolerance=1e-6):\n",
    "    # Get dimensions\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialize parameters\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "    \n",
    "    # Store costs for monitoring convergence\n",
    "    costs = []\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        # Forward pass\n",
    "        y_pred = np.dot(X, weights) + bias\n",
    "        \n",
    "        # Calculate cost (MSE)\n",
    "        cost = (1/(2*n_samples)) * np.sum((y_pred - y) ** 2)    # the 1/2 is for convenience in derivative calculation\n",
    "        costs.append(cost)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        # partial derivative of the cost function (MSE) with respect to weights\n",
    "        # need to understand more about \"why dot product?\"\n",
    "        d_weights = (1/n_samples) * np.dot(X.T, (y_pred - y))   # Matrix multiplication that gives us the gradient for each weight\n",
    "        # partial derivative of the cost function (MSE) with respect to bias\n",
    "        d_bias = (1/n_samples) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Update parameters\n",
    "        weights -= learning_rate * d_weights\n",
    "        bias -= learning_rate * d_bias\n",
    "        \n",
    "        # Check convergence\n",
    "        if iteration > 0 and abs(costs[-1] - costs[-2]) < tolerance:\n",
    "            print(f\"Converged at iteration {iteration}\")\n",
    "            break\n",
    "            \n",
    "    return weights, bias, costs\n",
    "\n",
    "# Example usage with normalized features\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([3, 5, 7, 9])\n",
    "\n",
    "# Normalize features\n",
    "X_normalized = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Train model\n",
    "weights, bias, costs = linear_regression(X_normalized, y)\n",
    "\n",
    "# Print results\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)\n",
    "print(\"Final cost:\", costs[-1])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = np.dot(X_normalized, weights) + bias\n",
    "print(\"Predictions:\", y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".aiop-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
